/**
 * ğŸ¨ å¢å¼ºå‹å¤šæ¨¡æ€è½¬æ¢å™¨
 * OpenAI API ä¸ VS Code LM API ä¹‹é—´çš„é©å‘½æ€§è½¬æ¢
 * âœ¨ å®Œå…¨æ”¯æŒå›¾åƒã€å‡½æ•°å’ŒåŠ¨æ€æ¨¡å‹ï¼
 */

import * as vscode from 'vscode';
import * as fs from 'fs';
import * as path from 'path';
import { 
    EnhancedMessage, 
    ModelCapabilities, 
    EnhancedRequestContext,
    ToolCall,
    FunctionDefinition 
} from '../types/ModelCapabilities';
import { 
    OpenAICompletionResponse, 
    OpenAIStreamResponse, 
    OpenAIModelsResponse,
    OpenAIModel
} from '../types/OpenAI';
import { logger } from './Logger';

export class Converter {
    
    /**
     * ğŸ¨ å°†å¢å¼ºæ¶ˆæ¯è½¬æ¢ä¸º VS Code LM API æ ¼å¼
     * âœ¨ æ”¯æŒå›¾åƒå’Œå¤šæ¨¡æ€å†…å®¹ï¼
     */
    public static async convertMessagesToVSCode(
        messages: EnhancedMessage[], 
        selectedModel: ModelCapabilities
    ): Promise<vscode.LanguageModelChatMessage[]> {
        const vsCodeMessages: vscode.LanguageModelChatMessage[] = [];
        
        for (const message of messages) {
            try {
                const vsCodeMessage = await this.convertSingleMessage(message, selectedModel);
                if (vsCodeMessage) {
                    vsCodeMessages.push(vsCodeMessage);
                }
            } catch (error) {
                logger.error(`è½¬æ¢æ¶ˆæ¯å¤±è´¥ï¼š`, error as Error, { message });
                // å›é€€åˆ°ä»…æ–‡æœ¬å†…å®¹
                if (typeof message.content === 'string') {
                    vsCodeMessages.push(new vscode.LanguageModelChatMessage(
                        this.mapRoleToVSCode(message.role),
                        this.formatRolePrefix(message.role) + message.content
                    ));
                }
            }
        }
        
        return vsCodeMessages;
    }
    
    /**
     * ğŸ“‹ è½¬æ¢å•ä¸ªå¢å¼ºæ¶ˆæ¯
     */
    private static async convertSingleMessage(
        message: EnhancedMessage, 
        selectedModel: ModelCapabilities
    ): Promise<vscode.LanguageModelChatMessage | null> {
        
        // å¤„ç†ç®€å•æ–‡æœ¬æ¶ˆæ¯
        if (typeof message.content === 'string') {
            return new vscode.LanguageModelChatMessage(
                this.mapRoleToVSCode(message.role),
                this.formatRolePrefix(message.role) + message.content
            );
        }
        
        // å¤„ç†å¤æ‚çš„å¤šæ¨¡æ€å†…å®¹
        if (Array.isArray(message.content)) {
            return await this.convertMultimodalMessage(message, selectedModel);
        }
        
        return null;
    }
    
    /**
     * ğŸ–¼ï¸ è½¬æ¢å¸¦å›¾åƒçš„å¤šæ¨¡æ€æ¶ˆæ¯
     */
    private static async convertMultimodalMessage(
        message: EnhancedMessage,
        selectedModel: ModelCapabilities
    ): Promise<vscode.LanguageModelChatMessage | null> {
        
        if (!Array.isArray(message.content)) {
            return null;
        }
        
    const contentParts: any[] = [];
        let textContent = this.formatRolePrefix(message.role);
        
        for (const part of message.content) {
            if (part.type === 'text' && part.text) {
                textContent += part.text;
                
            } else if (part.type === 'image_url' && part.image_url) {
                
                // ğŸ”¥ é©å‘½æ€§ï¼šå¦‚æœæ¨¡å‹æ”¯æŒè§†è§‰åˆ™å¤„ç†å›¾åƒï¼
                if (selectedModel.supportsVision) {
                    try {
                        const imageContent = await this.processImageContent(part.image_url.url);
                        if (imageContent) {
                            // å¦‚æœæˆ‘ä»¬æœ‰äºŒè¿›åˆ¶æ•°æ®ï¼ˆæ¥è‡ª data URI æˆ–æœ¬åœ°æ–‡ä»¶ï¼‰ï¼Œåˆ™åˆ›å»º LanguageModelDataPart å¹¶åŠ å…¥å†…å®¹
                            if (imageContent.data && imageContent.mimeType) {
                                const buffer = Buffer.from(imageContent.data, 'base64');
                                try {
                                    const DataPartCtor = (vscode as any).LanguageModelDataPart;
                                    if (DataPartCtor) {
                                        contentParts.push(new DataPartCtor(buffer, imageContent.mimeType));
                                    } else {
                                        // å¦‚æœè¿è¡Œæ—¶æ²¡æœ‰è¯¥æ„é€ å™¨ï¼Œé€€å›åˆ°æ–‡æœ¬å ä½
                                        textContent += `\n[Image: ${imageContent.description}]\n`;
                                    }
                                } catch (e) {
                                    // å¦‚æœåˆ›å»º DataPart å¤±è´¥ï¼Œé€€å›åˆ°æ–‡æœ¬å ä½
                                    logger.warn('æ— æ³•åˆ›å»º LanguageModelDataPartï¼Œé€€å›æ–‡æœ¬å ä½ï¼š', e as Error);
                                    textContent += `\n[Image: ${imageContent.description}]\n`;
                                }
                            } else {
                                // æ— äºŒè¿›åˆ¶æ•°æ®ï¼Œä»…æ·»åŠ æè¿°æ–‡æœ¬ï¼ˆä¾‹å¦‚è¿œç¨‹ URLï¼‰
                                textContent += `\n[Image: ${imageContent.description}]\n`;
                            }
                        }
                    } catch (error) {
                        logger.warn(`å¤„ç†å›¾åƒå¤±è´¥ï¼š`, error as Error);
                        textContent += `\n[Image: ${part.image_url.url}]\n`;
                    }
                } else {
                    logger.warn(`æ¨¡å‹ ${selectedModel.id} ä¸æ”¯æŒè§†è§‰ï¼Œè·³è¿‡å›¾åƒ`);
                    textContent += `\n[æ‰€é€‰æ¨¡å‹ä¸æ”¯æŒå›¾åƒ]\n`;
                }
            }
        }
        
        // å¦‚æœä»æœ‰æ–‡æœ¬å†…å®¹ï¼ˆæˆ–è€…æ²¡æœ‰ç›´æ¥æ·»åŠ  DataPartï¼‰ï¼Œåˆ™æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
        if (textContent && textContent.trim().length > 0) {
            contentParts.push(new vscode.LanguageModelTextPart(textContent));
        }
        
        // ä½¿ç”¨æ­£ç¡®çš„è§’è‰²æ˜ å°„åˆ›å»ºæ¶ˆæ¯
        return new vscode.LanguageModelChatMessage(
            this.mapRoleToVSCode(message.role),
            contentParts
        );
    }
    
    /**
     * ğŸ–¼ï¸ å¤„ç†å›¾åƒå†…å®¹ï¼ˆBase64ã€URL æˆ–æ–‡ä»¶è·¯å¾„ï¼‰
     */
    private static async processImageContent(imageUrl: string): Promise<{ description: string; data?: string; mimeType?: string } | null> {
        try {
            // å¤„ç†ä¸åŒçš„å›¾åƒæº
            if (imageUrl.startsWith('data:image/')) {
                // Base64 ç¼–ç å›¾åƒ
                const [header, data] = imageUrl.split(',');
                const mimeType = header.match(/data:([^;]+)/)?.[1] || 'image/jpeg';
                return {
                    description: `Base64 ${mimeType} image`,
                    data: data,
                    mimeType
                };
                
            } else if (imageUrl.startsWith('http://') || imageUrl.startsWith('https://')) {
                // URL å›¾åƒ - å‡ºäºå®‰å…¨è€ƒè™‘ï¼Œæˆ‘ä»¬åªè®°å½•å®ƒ
                return {
                    description: `Remote image from ${new URL(imageUrl).hostname}`
                };
                
            } else if (imageUrl.startsWith('file://') || await this.fileExists(imageUrl)) {
                // æœ¬åœ°æ–‡ä»¶
                const filePath = imageUrl.startsWith('file://') ? imageUrl.slice(7) : imageUrl;
                const ext = path.extname(filePath).toLowerCase();
                const supportedFormats = ['.jpg', '.jpeg', '.png', '.gif', '.webp'];
                
                if (supportedFormats.includes(ext)) {
                    try {
                        const stats = await fs.promises.stat(filePath);
                        // å°è¯•è¯»å–ä¸º base64ï¼Œä»¥ä¾¿ä¸Šå±‚å¯ä»¥ç›´æ¥åˆ›å»º DataPart
                        try {
                            const buf = await fs.promises.readFile(filePath);
                            const mimeType = ext === '.png' ? 'image/png' : (ext === '.jpg' || ext === '.jpeg' ? 'image/jpeg' : `image/${ext.slice(1)}`);
                            return {
                                description: `Local ${ext.slice(1)} image (${(stats.size / 1024).toFixed(1)}KB)`,
                                data: buf.toString('base64'),
                                mimeType
                            };
                        } catch (readErr) {
                            return {
                                description: `Local ${ext.slice(1)} image (${(stats.size / 1024).toFixed(1)}KB)`
                            };
                        }
                    } catch (error) {
                        return {
                            description: `Local ${ext.slice(1)} image (size unknown)`
                        };
                    }
                }
            }
            
            return null;
        } catch (error) {
            logger.error('Error processing image:', error as Error);
            return null;
        }
    }
    
    /**
     * ğŸ”„ å°† OpenAI è§’è‰²æ˜ å°„åˆ° VS Code è§’è‰²
     */
    private static mapRoleToVSCode(role: string): vscode.LanguageModelChatMessageRole {
        switch (role) {
            case 'system':
            case 'user':
                return vscode.LanguageModelChatMessageRole.User;
            case 'assistant':
                return vscode.LanguageModelChatMessageRole.Assistant;
            default:
                return vscode.LanguageModelChatMessageRole.User;
        }
    }
    
    /**
     * ğŸ·ï¸ ä¸ºå†…å®¹æ ¼å¼åŒ–è§’è‰²å‰ç¼€
     */
    private static formatRolePrefix(role: string): string {
        switch (role) {
            case 'system':
                return 'System: ';
            case 'assistant':
                return 'Assistant: ';
            case 'user':
            default:
                return '';
        }
    }
    
    /**
     * ğŸ“ åˆ›å»ºå¢å¼ºå®Œæˆå“åº”
     */
    public static createCompletionResponse(
        content: string,
        context: EnhancedRequestContext,
        selectedModel: ModelCapabilities
    ): OpenAICompletionResponse {
        const now = Math.floor(Date.now() / 1000);
        
        return {
            id: `chatcmpl-${context.requestId}`,
            object: 'chat.completion',
            created: now,
            model: context.model, // ä½¿ç”¨è¯·æ±‚çš„æ¨¡å‹åç§°
            choices: [{
                index: 0,
                message: {
                    role: 'assistant',
                    content: content
                },
                finish_reason: 'stop'
            }],
            usage: {
                prompt_tokens: context.estimatedTokens,
                completion_tokens: this.estimateTokens(content),
                total_tokens: context.estimatedTokens + this.estimateTokens(content)
            },
            system_fingerprint: `vs-code-${selectedModel.vendor}-${selectedModel.family}`
        };
    }
    
    /**
     * ğŸŒŠ åˆ›å»ºå¢å¼ºæµå¼å“åº”å—
     */
    public static createStreamChunk(
        content: string,
        context: EnhancedRequestContext,
        selectedModel: ModelCapabilities,
        isFirst: boolean = false,
        isLast: boolean = false
    ): OpenAIStreamResponse {
        const now = Math.floor(Date.now() / 1000);
        
        const chunk: OpenAIStreamResponse = {
            id: `chatcmpl-${context.requestId}`,
            object: 'chat.completion.chunk',
            created: now,
            model: context.model, // ä½¿ç”¨è¯·æ±‚çš„æ¨¡å‹åç§°
            choices: [{
                index: 0,
                delta: {},
                finish_reason: isLast ? 'stop' : null
            }],
            system_fingerprint: `vs-code-${selectedModel.vendor}-${selectedModel.family}`
        };
        
        if (isFirst) {
            chunk.choices[0].delta.role = 'assistant';
        }
        
        if (content) {
            chunk.choices[0].delta.content = content;
        }
        
        return chunk;
    }
    
    /**
     * ğŸ“‹ åˆ›å»ºåŠ¨æ€æ¨¡å‹å“åº”
     */
    public static createModelsResponse(availableModels: ModelCapabilities[]): OpenAIModelsResponse {
        const now = Math.floor(Date.now() / 1000);
        
        const models: OpenAIModel[] = availableModels.map(model => ({
            id: model.id,
            object: 'model',
            created: now,
            owned_by: model.vendor || 'vs-code',
            // æ·»åŠ å…³äºèƒ½åŠ›çš„è‡ªå®šä¹‰å…ƒæ•°æ®
            permission: [{
                id: `perm-${model.id}`,
                object: 'model_permission',
                created: now,
                allow_create_engine: false,
                allow_sampling: true,
                allow_logprobs: false,
                allow_search_indices: false,
                allow_view: true,
                allow_fine_tuning: false,
                organization: model.vendor || 'vs-code',
                is_blocking: false
            }]
        }));
        
        return {
            object: 'list',
            data: models
        };
    }
    
    /**
     * ğŸŒŠ ä»å¸¦æœ‰å¢å¼ºä¸Šä¸‹æ–‡çš„ VS Code LM å“åº”æµä¸­æå–å†…å®¹
     */
    public static async *extractStreamContent(
        response: vscode.LanguageModelChatResponse,
        context: EnhancedRequestContext,
        selectedModel: ModelCapabilities
    ): AsyncGenerator<string> {
        let isFirst = true;
        
        try {
            for await (const chunk of response.text) {
                if (chunk) {
                    yield this.createSSEEvent('data', this.createStreamChunk(
                        chunk,
                        context,
                        selectedModel,
                        isFirst,
                        false
                    ));
                    isFirst = false;
                }
            }
            
            // å‘é€æœ€ç»ˆå—
            yield this.createSSEEvent('data', this.createStreamChunk(
                '',
                context,
                selectedModel,
                false,
                true
            ));
            
            // å‘é€å®Œæˆä¿¡å·
            yield this.createSSEEvent('done');
            
        } catch (error) {
            logger.error('å¢å¼ºæµæå–ä¸­å‡ºé”™', error as Error, {}, context.requestId);
            yield this.createSSEEvent('error', {
                message: 'å¢å¼ºæµå¤„ç†é”™è¯¯',
                type: 'api_error'
            });
        }
    }
    
    /**
     * ğŸ“ ä» VS Code LM å“åº”ä¸­æ”¶é›†æ‰€æœ‰å†…å®¹
     */
    public static async collectFullResponse(
        response: vscode.LanguageModelChatResponse
    ): Promise<string> {
        let fullContent = '';
        
        try {
            for await (const chunk of response.text) {
                fullContent += chunk;
            }
        } catch (error) {
            logger.error('æ”¶é›†å¢å¼ºå“åº”æ—¶å‡ºé”™', error as Error);
            throw new Error('æ”¶é›†å“åº”å†…å®¹å¤±è´¥');
        }
        
        return fullContent;
    }
    
    /**
     * ğŸ”„ åˆ›å»ºæœåŠ¡å™¨å‘é€äº‹ä»¶æ•°æ®
     */
    public static createSSEEvent(type: 'data' | 'done' | 'error', data?: any): string {
        switch (type) {
            case 'data':
                return `data: ${JSON.stringify(data)}\n\n`;
            case 'done':
                return 'data: [DONE]\n\n';
            case 'error':
                return `data: ${JSON.stringify({ error: data })}\n\n`;
            default:
                return '';
        }
    }
    
    /**
     * ğŸ“ˆ å¢å¼ºä»¤ç‰Œä¼°ç®—
     */
    private static estimateTokens(text: string): number {
        // æ›´ç²¾ç»†çš„ä»¤ç‰Œä¼°ç®—
        // è€ƒè™‘ä¸åŒè¯­è¨€å’Œç‰¹æ®Šä»¤ç‰Œ
        const baseTokens = Math.ceil(text.length / 4);
        const specialTokens = (text.match(/[\n\r\t]/g) || []).length;
        return baseTokens + specialTokens;
    }
    
    /**
     * ğŸ¯ åˆ›å»ºå¢å¼ºè½¬æ¢ä¸Šä¸‹æ–‡
     */
    public static createEnhancedContext(
        requestId: string,
        modelId: string,
        isStream: boolean,
        messages: EnhancedMessage[],
        selectedModel?: ModelCapabilities,
        clientIP?: string,
        userAgent?: string
    ): EnhancedRequestContext {
        
        // åˆ†ææ¶ˆæ¯å†…å®¹ä»¥è·å–èƒ½åŠ›
        const hasImages = messages.some(msg => 
            Array.isArray(msg.content) && 
            msg.content.some(part => part.type === 'image_url')
        );
        
        const hasFunctions = messages.some(msg => 
            msg.tool_calls && msg.tool_calls.length > 0
        );
        
        // ä¼°ç®—æ€»ä»¤ç‰Œæ•°
        const estimatedTokens = messages.reduce((total, msg) => {
            if (typeof msg.content === 'string') {
                return total + this.estimateTokens(msg.content);
            } else if (Array.isArray(msg.content)) {
                return total + msg.content.reduce((partTotal, part) => {
                    if (part.type === 'text' && part.text) {
                        return partTotal + this.estimateTokens(part.text);
                    }
                    return partTotal + 100; // å›¾åƒä¼°ç®—
                }, 0);
            }
            return total;
        }, 0);
        
        // ç¡®å®šæ‰€éœ€èƒ½åŠ›
        const requiredCapabilities: string[] = [];
        if (hasImages) {
            requiredCapabilities.push('supportsVision');
        }
        if (hasFunctions) {
            requiredCapabilities.push('supportsTools');
        }
        if (isStream) {
            requiredCapabilities.push('supportsStreaming');
        }
        
        return {
            requestId,
            model: modelId,
            isStream,
            startTime: new Date(),
            clientIP,
            userAgent,
            hasImages,
            hasFunctions,
            requiredCapabilities,
            estimatedTokens,
            selectedModel
        };
    }
    
    /**
     * ğŸ§¹ è§£æå’Œå¢å¼ºè¯·æ±‚ä½“
     */
    public static parseEnhancedRequestBody(body: string): {
        messages: EnhancedMessage[];
        model?: string;
        stream?: boolean;
        functions?: FunctionDefinition[];
        tools?: any[];
        [key: string]: any;
    } {
        try {
            const parsed = JSON.parse(body);
            
            // ç¡®ä¿æ¶ˆæ¯å…·æœ‰æ­£ç¡®çš„ç±»å‹
            if (parsed.messages && Array.isArray(parsed.messages)) {
                parsed.messages = parsed.messages.map((msg: any) => {
                    // å¦‚æœ‰éœ€è¦ï¼Œå°†æ—§å¼å†…å®¹è½¬æ¢ä¸ºæ–°çš„å¢å¼ºæ ¼å¼
                    if (typeof msg.content === 'string') {
                        return msg as EnhancedMessage;
                    }
                    
                    // å¤„ç†å¤šæ¨¡æ€å†…å®¹
                    if (Array.isArray(msg.content)) {
                        return {
                            ...msg,
                            content: msg.content.map((part: any) => {
                                if (typeof part === 'string') {
                                    return { type: 'text', text: part };
                                }
                                return part;
                            })
                        } as EnhancedMessage;
                    }
                    
                    return msg as EnhancedMessage;
                });
            }
            
            return parsed;
        } catch (error) {
            throw new Error('è¯·æ±‚ä½“ä¸­çš„ JSON æ— æ•ˆ');
        }
    }
    
    /**
     * ğŸ“Š åˆ›å»ºå¸¦æœ‰æ¨¡å‹ä¿¡æ¯çš„å¥åº·æ£€æŸ¥å“åº”
     */
    public static createHealthResponse(serverState: any, modelPool?: any) {
        return {
            status: 'ok',
            timestamp: new Date().toISOString(),
            server: {
                running: serverState.isRunning,
                uptime: serverState.startTime ? Date.now() - serverState.startTime.getTime() : 0,
                requests: serverState.requestCount,
                errors: serverState.errorCount,
                activeConnections: serverState.activeConnections
            },
            models: modelPool ? {
                total: modelPool.primary.length + modelPool.secondary.length + modelPool.fallback.length,
                primary: modelPool.primary.length,
                secondary: modelPool.secondary.length,
                fallback: modelPool.fallback.length,
                unhealthy: modelPool.unhealthy.length,
                supportsVision: modelPool.primary.filter((m: any) => m.supportsVision).length,
                supportsTools: modelPool.primary.filter((m: any) => m.supportsTools).length
            } : undefined
        };
    }
    
    /**
     * ğŸ” å¼‚æ­¥æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
     */
    private static async fileExists(filePath: string): Promise<boolean> {
        try {
            await fs.promises.access(filePath);
            return true;
        } catch {
            return false;
        }
    }

    /**
     * ğŸš€ åˆ›å»º OpenAI æ ¼å¼çš„é”™è¯¯å“åº”
     */
    public static createErrorResponse(
        message: string,
        type: string = 'api_error',
        code?: string,
        param?: string
    ) {
        return {
            error: {
                message,
                type,
                code,
                param
            }
        };
    }
}
